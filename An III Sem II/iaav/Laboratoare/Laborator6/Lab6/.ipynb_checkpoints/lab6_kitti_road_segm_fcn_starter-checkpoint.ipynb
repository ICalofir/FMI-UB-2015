{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWC9X_-tS0l4"
   },
   "source": [
    "# Laborator 6 - Segmentare Semantică\n",
    "\n",
    "În acest laborator veți construi și antrena o rețea complet convoluțională (***FCN - Fully Convolutional Network***), al cărei rezultat este o imagine (nu doar o clasificare). Veți implementa trei tehnici speciale: ***convoluții 1x1***, ***upsampling*** și ***skip layers*** pentru a vă antrena propriul FCN.\n",
    "\n",
    "Veți începe de la un model pre-antrenat pe ImageNet (***VGG16***). După eliminarea straturilor de clasificare (fully connected layers), veți putea adăuga cele trei tehnici (conv. 1x1, upsampling și skip layers) pentru a obține un FCN capabil să clasifice fiecare pixel din imagine.\n",
    "\n",
    "Veți construi o rețea de segmentare semantică pentru a identifica spațiul liber pe drum (veți folosi setul de date [Kitti Road](http://www.cvlibs.net/datasets/kitti/eval_road.php)).\n",
    "\n",
    "## De ce FCN?\n",
    "\n",
    "O rețea convoluțională normală constă dintr-o serie de straturi convoluționale, urmată de straturi fully connected și, în cele din urmă, de o funcție de activare Softmax. Aceasta este o arhitectură bună pentru clasificare, însă straturile fully connected nu păstrează informația spațială. FCN păstrează informația spațială în întreaga rețea (FCN funcționează cu imagini de orice dimensiune).\n",
    "\n",
    "Din punct de vedere structural, FCN este compusă din două părți: encoder (VGG, ResNet - extrage caracteristici din imagine) și decoder (mărește outputul encoderului pentru a fi de aceeași dimensiune ca imaginea originală; astfel, se realizează clasificarea fiecărui pixel individual din imaginea originală)\n",
    "\n",
    "---\n",
    "\n",
    "![alt text](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/05d20ad124a8696f387e6c9632dec0b31251df64/4-Figure3-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fI2DlmjZDyAR"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rHMvCqvAFqCy"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!apt-get update\n",
    "!apt-get install ffmpeg\n",
    "!pip install moviepy tqdm\n",
    "\n",
    "# Download & Extract the Kitti Road dataset\n",
    "!mkdir ./data ./runs ./saved_models\n",
    "!wget --progress=bar:force http://kitti.is.tue.mpg.de/kitti/data_road.zip -P ./data\n",
    "!unzip ./data/data_road.zip -d ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "08wPydwvFiWZ"
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import tensorflow as tf\n",
    "import helper\n",
    "import warnings\n",
    "from distutils.version import LooseVersion\n",
    "import project_tests as tests\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "oCm2peGHA8x0"
   },
   "outputs": [],
   "source": [
    "# Descărcați modelul VGG pre-antrenat\n",
    "\n",
    "num_classes = 2\n",
    "image_shape = (160, 576)\n",
    "data_dir = './data'\n",
    "runs_dir = './runs'\n",
    "\n",
    "helper.maybe_download_pretrained_vgg(data_dir)\n",
    "tests.test_for_kitti_dataset(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5fxnI7Fnr8TH"
   },
   "source": [
    "### Vizualizare dataset Kitti Road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "c94nEukbr2xT"
   },
   "outputs": [],
   "source": [
    "num_samples = 5\n",
    "get_batches_fn = helper.gen_batch_function(os.path.join(data_dir, 'data_road/training'), image_shape)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for batch, (images, labels) in enumerate(get_batches_fn(num_samples)):\n",
    "  for i, (image, label) in enumerate(zip(images, labels)):\n",
    "    plt.subplot(num_samples, 2, 2*i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, None)\n",
    "    plt.subplot(num_samples, 2, 2*i+2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(label[:,:,0], 'jet')\n",
    "    \n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UbYlXAZMFmuz"
   },
   "outputs": [],
   "source": [
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "G0elY8-KGWX7"
   },
   "outputs": [],
   "source": [
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P7uOFiTcq_np"
   },
   "source": [
    "## Cerința 1 - Încărcați în Tensorflow modelul VGG pre-antrenat și obțineți tensorii corespunzători layerelor image_input, pool3, pool4, conv_7, precum și keep_prob (pentru dropout în timpul procesului de fine-tuning)\n",
    "\n",
    "* Folosiți [`tf.saved_model.loader.load`](https://www.tensorflow.org/api_docs/python/tf/saved_model/loader/load) pentru a încărca modelul și parametrii\n",
    "* Folosiți [`tf.get_default_graph`](https://www.tensorflow.org/api_docs/python/tf/get_default_graph) pentru a obține graful default pentru threadul curent\n",
    "* Folosiți [`graph.get_tensor_by_name`](https://www.tensorflow.org/api_docs/python/tf/Graph) pentru a obține tensorii din modelul VGG\n",
    "\n",
    "![alt text](https://csdl-images.computer.org/trans/tp/2017/04/figures/shelh3-2572683.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FaKNLnaZGeqL"
   },
   "outputs": [],
   "source": [
    "def load_vgg(sess, vgg_path):\n",
    "    \"\"\"\n",
    "    Încărcați în Tensorflow modelul VGG pre-antrenat\n",
    "    :param sess: Sesiunea Tensorflow\n",
    "    :param vgg_path: Calea către directorul vgg, conținând \"variables/\" și \"saved_model.pb\"\n",
    "    :return: Tuplu de Tensori din modelul VGG (image_input, keep_prob, layer3_out, layer4_out, layer7_out)\n",
    "    \"\"\"\n",
    "    # TODO: Implementați funcția\n",
    "    # Folosiți tf.saved_model.loader.load pentru a încărca modelul și parametrii\n",
    "    vgg_tag = 'vgg16'\n",
    "    vgg_input_tensor_name = 'image_input:0'\n",
    "    vgg_keep_prob_tensor_name = 'keep_prob:0'\n",
    "    vgg_layer3_out_tensor_name = 'layer3_out:0'\n",
    "    vgg_layer4_out_tensor_name = 'layer4_out:0'\n",
    "    vgg_layer7_out_tensor_name = 'layer7_out:0'\n",
    "    \n",
    "    return None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ciWk3n1fGh5y"
   },
   "outputs": [],
   "source": [
    "tests.test_load_vgg(load_vgg, tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8gNhGmVtF20"
   },
   "source": [
    "## Cerința 2 - Adăugați layerele corespunzătoare decoderului. Construiți skip-layers folosind layerele vgg\n",
    "\n",
    "* pentru a evita problema exploziei gradienților, folosiți [***`tf.multiply`***](https://www.tensorflow.org/api_docs/python/tf/multiply) pentru a scala rezultatul layerelor de pooling 3 și 4 înainte de a aplica convoluțiile 1x1 (folosiți `0.0001` pentru pool_3 și `0.01` pentru pool_4)\n",
    "* folosiți [***`tf.layers.conv2d`***](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d) pentru a adăuga convoluțiile 1x1, pentru a reduce depth-ul layerelor la numărul de clase\n",
    "* folosiți [***`tf.layers.conv2d_transpose`***](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d_transpose) pentru a mări rezoluția layerelor (2x pentru conv_7, 2x pentru primul skip-layer (între pool_4 și conv_7 upscaled) și 8x pentru cel de-al 2-lea skip layer (între pool_3 și primul skip-layer upscaled))\n",
    "* folosiți [***`tf.add`***](https://www.tensorflow.org/api_docs/python/tf/add) pentru skip-layers\n",
    "\n",
    "***Hint: Folosiți regularizare L2 pentru a preveni overfitting-ul ([`tf.contrib.layers.l2_regularizer`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/l2_regularizer))***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "S08OD8kJGkVT"
   },
   "outputs": [],
   "source": [
    "def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n",
    "    \"\"\"\n",
    "    Creați layerele pentru FCN; construiți skip-layers folosind layerele vgg\n",
    "    :param vgg_layer3_out: Tensor pentru layerul 3\n",
    "    :param vgg_layer4_out: Tensor pentru layerul 4\n",
    "    :param vgg_layer7_out: Tensor pentru layerul 7\n",
    "    :param num_classes: Numărul de clase\n",
    "    :return: Tensorul pentru layerul de output\n",
    "    \"\"\"\n",
    "    # TODO: Implementați funcția\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "szLhOEreGqMk"
   },
   "outputs": [],
   "source": [
    "tests.test_layers(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wSqF_zcv5A4R"
   },
   "source": [
    "## Cerința 3 - Adăugați operațiile de loss și optimizare\n",
    "\n",
    "* folosiți [***`tf.nn.softmax_cross_entropy_with_logits`***](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits) ca funcție de loss\n",
    "* folosiți [***`tf.train.AdamOptimizer`***](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer) ca optimizator\n",
    "\n",
    "***Hint: ***\n",
    " * ***trebuie să însumați loss-ul de regularizare cu loss-ul cross-entropy pentru ca regularizarea să aibă loc (folosiți [`tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES`)](https://www.tensorflow.org/api_docs/python/tf/get_collection) pentru a obține loss-ul de regularizare)***\n",
    " * *** `nn_last_layer` și `correct_label` trebuie redimensionați pentru a deveni 2D (fiecare rând va reprezenta un pixel, iar fiecare coloană va reprezenta o clasă)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "CUcj5y_FGsWq"
   },
   "outputs": [],
   "source": [
    "def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n",
    "    \"\"\"\n",
    "    Adăugați operațiile de loss și optimizare\n",
    "    :param nn_last_layer: Tensor pentru ultimul layer din rețea\n",
    "    :param correct_label: Placeholder pentru imaginea ground-truth (imaginea label/mască)\n",
    "    :param learning_rate: Placeholder pentru learning rate\n",
    "    :param num_classes: Numărul de clase\n",
    "    :return: (logits, optimizer, cross_entropy_loss)\n",
    "    \"\"\"\n",
    "    # TODO: Implementați funcția\n",
    "    \n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EHkGpLTrGwsa"
   },
   "outputs": [],
   "source": [
    "tests.test_optimize(optimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enz8BOiI-C1h"
   },
   "source": [
    "## Cerința 4 - Antrenați rețeaua și afișați loss-ul în timpul antrenării\n",
    "* folosiți `0.5` pentru dropout\n",
    "* folosiți `1e-4` pentru learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZZNBsvKRGzSs"
   },
   "outputs": [],
   "source": [
    "def train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n",
    "             correct_label, keep_prob, learning_rate):\n",
    "    \"\"\"\n",
    "    Antrenați rețeaua și afișați loss-ul în timpul antrenării\n",
    "    :param sess: Sesiunea Tensorflow\n",
    "    :param epochs: Numărul de epoci\n",
    "    :param batch_size: Dimensiunea batch-ului de imagini\n",
    "    :param get_batches_fn: Funcție pentru a obține batch-uri de imagini. Apelați folosind get_batches_fn(batch_size)\n",
    "    :param train_op: Operație Tensorflow pentru a antrena rețeaua neurală\n",
    "    :param cross_entropy_loss: Tensor pentru loss\n",
    "    :param input_image: Placeholder pentru imagini\n",
    "    :param correct_label: Placeholder pentru labeluri\n",
    "    :param keep_prob: Placeholder pentru dropout\n",
    "    :param learning_rate: Placeholder pentru learning rate\n",
    "    \"\"\"\n",
    "    # TODO: Implementați funcția\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fcQ4QBwG_Ymu"
   },
   "source": [
    "## BONUS 1 - Aplicați rețeaua neurală pe un video\n",
    "\n",
    "Metoda `process_image` primește un frame RGB, aplică rețeaua neurală pentru a segmenta drumul (obține o mască), aplică masca peste imaginea originală și o întoarce la output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uEGOZyY2G5Vq"
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \"\"\"\n",
    "    Aplică rețeaua neurală unui frame dintr-un video pentru a segmenta drumul\n",
    "    : param image: Frame RGB\n",
    "    : return: Imagine RGB cu masca drumului aplicată\n",
    "    \"\"\"\n",
    "    # TODO: Implementați funcția\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jLWWz0gMFPWK"
   },
   "outputs": [],
   "source": [
    "train_model = True\n",
    "process_video = False\n",
    "load_model = False\n",
    "save_model = False\n",
    "output_dir = None\n",
    "\n",
    "# process image parameters\n",
    "sess = tf.Session()\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "loggits = tf.placeholder(tf.int32, [None, None, None, 2])\n",
    "input_image = tf.placeholder(tf.int32, [None, None, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "52EtJ2ANG8Z3"
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    global image_shape, logits, sess, keep_prob, input_image, output_dir\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # Path to vgg model\n",
    "        vgg_path = os.path.join(data_dir, 'vgg')\n",
    "        # Create function to get batches\n",
    "        get_batches_fn = helper.gen_batch_function(os.path.join(data_dir, 'data_road/training'), image_shape)\n",
    "        \n",
    "        epochs = 30\n",
    "        batch_size = 8\n",
    "        learning_rate = tf.placeholder(tf.float32)\n",
    "        correct_label = tf.placeholder(tf.int32, [None, None, None, num_classes])\n",
    "\n",
    "        # TODO: Construiți rețeaua apelând metodele load_vgg, layers și optimize\n",
    "        pass\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        if load_model:\n",
    "            checkpoint = tf.train.get_checkpoint_state('./saved_models')\n",
    "            try:\n",
    "                saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "                print('Successfully loaded {}'.format(checkpoint.model_checkpoint_path))\n",
    "            except:\n",
    "                print('Could not find network weights')\n",
    "\n",
    "        # TODO: Antrenați rețeaua apelând metoda train_nn\n",
    "        if train_model:\n",
    "            pass\n",
    "\n",
    "        # Salvează imaginile de output folosind helper.save_inference_samples\n",
    "        # output_dir = helper.save_inference_samples(runs_dir, data_dir, sess, image_shape, logits, keep_prob, input_image)\n",
    "        \n",
    "        if save_model:\n",
    "            saver.save(sess, './saved_models/model')\n",
    "\n",
    "        # BONUS 1 - Aplicați rețeaua pe un video\n",
    "        if process_video:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pu1rovDwQJJ5"
   },
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HkEok8EDIMec"
   },
   "source": [
    "### Vizualizare output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uikGW-rlKij0"
   },
   "outputs": [],
   "source": [
    "if output_dir:\n",
    "  num_samples = 10\n",
    "  image_list = glob.glob(os.path.join(output_dir, '*.png'))\n",
    "  img_height, img_width = image_shape\n",
    "\n",
    "  samples = random.sample(image_list, num_samples)\n",
    "\n",
    "  plt.figure(figsize=(10, 30))\n",
    "\n",
    "  for i, sample in enumerate(samples):\n",
    "    img = mpimg.imread(sample)\n",
    "    plt.subplot(num_samples, 1, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-10Z1CnVCG3V"
   },
   "source": [
    "## BONUS 2 - Augmentați imaginile pentru rezultate mai bune \n",
    " * [how-to-prepare-augment-images-for-neural-network](https://datascience.stackexchange.com/questions/5224/how-to-prepare-augment-images-for-neural-network)\n",
    " \n",
    "## BONUS 3 - Antrenați rețeaua pe setul de date [cityscapes](https://www.cityscapes-dataset.com/)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "lab6_kitti_road_segm_fcn_starter.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
